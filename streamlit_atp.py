import streamlit as st
import pandas as pd
import numpy as np
#import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import io

df = pd.read_csv('atp_data.csv')

st.title("Paris Sportifs Tennis üéæ")
st.sidebar.title("Sommaire")
pages=["Introduction", "Exploration", "Visualisation", "Nettoyage des donn√©es", "Pr√©paration pour l'entrainement des mod√®les","Machine learning", "Calcul des probabilit√©s", "Conclusion"]
page=st.sidebar.radio("S√©lectionnez une partie", pages)


st.sidebar.markdown("[Luc DOMPEYRE](https://www.linkedin.com/in/luc-dompeyre/)")



if page == pages[0] :
    st.write("### Introduction")
  
    st.write("Dans ce projet, mon objectif est de **pr√©dire de mani√®re plus pr√©cises que celles des bookmakers les r√©sultats des matchs de tennis ATP** et ceci via l'entra√Ænement d'un mod√®le performant de Machine Learning.")
  
    st.write("Avant d‚Äôattaquer la mod√©lisation, j'ai explor√© et nettoy√© les donn√©es afin d‚Äôobtenir un dataset fiable et exploitable. J'ai √©galement identifi√© et corrig√© des erreurs d'ex√©cution pour assurer la coh√©rence des analyses.")
    st.image("pexels-rajtatavarthy-171568.jpg")
  
if page == pages[1] :
    st.write("### Exploration")
  
    st.write("J'ai d'abord examin√© la structure du dataset en v√©rifiant les types de donn√©es, la pr√©sence de valeurs manquantes et d‚Äô√©ventuelles incoh√©rences. Cette premi√®re analyse m'a permis d‚Äôanticiper et d‚Äô√©viter des erreurs d‚Äôex√©cution lors du traitement des donn√©es.")
  
    st.write("Les donn√©es utilis√©es dans cette √©tude proviennent de [Kaggle](https://www.kaggle.com/datasets/edouardthomas/atp-matches-dataset) et comprennent 44709 lignes et 23 colonnes. Elles regroupent diverses informations sur les matchs ATP, comme les joueurs, les surfaces, les classements et les c√¥tes des bookmakers. Une exploration approfondie a √©t√© n√©cessaire pour comprendre la pertinence de chaque variable et assurer une utilisation optimale dans mes mod√®les pr√©dictifs.")
  
    st.write("### Pr√©sentation des variables du dataset :")
    st.write("<span style='color:red'>Location</span> : Localisation du tournoi", unsafe_allow_html=True)
    st.write("<span style='color:red'>Tournament</span> : Nom du tournoi", unsafe_allow_html=True)
    st.write("<span style='color:red'>Date</span> : Date du match", unsafe_allow_html=True)
    st.write("<span style='color:red'>Series, Court, Surface</span> : Type de comp√©tition et surface du match", unsafe_allow_html=True)
    st.write("<span style='color:red'>Round, Best of</span> : Tour du tournoi et format du match (meilleur des 3 ou 5 sets)", unsafe_allow_html=True)
    st.write("<span style='color:red'>Winner, Loser</span> : Noms du vainqueur et du perdant", unsafe_allow_html=True)
    st.write("<span style='color:red'>WRank, LRank</span> : Classement ATP du vainqueur et du perdant", unsafe_allow_html=True)
    st.write("<span style='color:red'>Wsets, Lsets</span> : Nombre de sets gagn√©s par le vainqueur et par le perdant", unsafe_allow_html=True)
    st.write("<span style='color:red'>Comment</span> : Indique si le match a √©t√© termin√© normalement ou si un √©v√©nement est venu perturb√© l‚Äôissu du match", unsafe_allow_html=True) 
    st.write("<span style='color:red'>PSW, PSL, B365W, B365L</span> : C√¥tes des bookmakers Pinnacles Sport et Bet365 pour les joueurs", unsafe_allow_html=True)
    st.write("<span style='color:red'>elo_winner, elo_loser</span> : Classement Elo des joueurs", unsafe_allow_html=True)
    st.write("<span style='color:red'>proba_elo</span> : Probabilit√© de victoire qu‚Äôavait le vainqueur bas√©e sur le classement Elo", unsafe_allow_html=True)

  
    st.write("### Affichage des premi√®res lignes du dataset pour avoir un premier aper√ßu:")
    st.dataframe(df.head(10))
  
    st.header("Informations sur le jeu de donn√©es")

# Capture la sortie de df.info() dans un buffer
    buffer = io.StringIO()
    df.info(buf=buffer)
    info_string = buffer.getvalue()

    # Affiche les informations dans un conteneur code
    st.code(info_string, language="text")
    
    st.write("Apr√®s v√©rification des types des variables, je remarque que la variable <span style='color:red'>Date</span> n‚Äôest pas au format **‚Äòdatetime‚Äô**, je modifierai son type dans la pr√©paration du jeu de donn√©es.", unsafe_allow_html=True)
  
    st.write('Le **nombre de doublons** est :',df.duplicated().sum())
  
    st.write("### Nombre de valeurs manquantes par lignes")
    st.write(df.isnull().sum())

if page == pages[2] :
    st.title("Visualisation")

#1er graphique
  
  # Cr√©ation du pie chart avec pourcentage
    surface_distribution = df['Surface'].value_counts()
    st.write("### Distribution des matchs par type de surface")

    fig, ax = plt.subplots(figsize=(8, 8))
    ax.pie(
    surface_distribution,
    labels=surface_distribution.index,
    autopct='%1.1f%%',
    startangle=90,
    colors=sns.color_palette("Set2", len(surface_distribution)))
    st.pyplot(fig)

#2eme graphique
    def target(row):
            return row["WRank"] <= row["LRank"]

    df['target'] = df.apply(lambda row: target(row), axis=1)

# Interface Streamlit
    st.write("### Comparaison du classement du vainqueur vs classement du perdant")
    st.write(" ")

    fig, ax = plt.subplots(figsize=(10, 6))
    sns.scatterplot(
    x='WRank', y='LRank', data=df, hue='target',
    palette={True: 'blue', False: 'green'}, s=50, alpha=0.6, ax=ax
    )

    # Tracer une ligne diagonale (y = x)
    ax.plot([df['WRank'].min(), df['WRank'].max()],
    [df['WRank'].min(), df['WRank'].max()],
    color='red', linestyle='dashed', linewidth=2, label='√âgalit√© de classement')

    # L√©gendes et titres
    ax.legend(title='Gagnant mieux class√©', loc='upper right')
    ax.set_title('Nuage de points entre le classement du gagnant et du perdant', fontsize=14)
    ax.set_xlabel('Classement du gagnant (WRank)', fontsize=12)
    ax.set_ylabel('Classement du perdant (LRank)', fontsize=12)

    # Affichage du graphique dans Streamlit
    st.pyplot(fig)
    st.write(" ")
    
#3eme graphique
# Calcul de la distribution en pourcentage
    comment_distribution = df['Comment'].value_counts(normalize=True) * 100

# Interface Streamlit
    st.write("### Distribution des matchs par type de commentaire")
    st.write(" ")
    # Cr√©ation du graphique
    fig, ax = plt.subplots(figsize=(10, 6))
    comment_distribution.plot(kind='bar', color=sns.color_palette("Set3", len(comment_distribution)), ax=ax)

    # Ajouter un titre et des labels
    ax.set_xlabel('Type de commentaire', fontsize=12)
    ax.set_ylabel('Pourcentage de matchs (%)', fontsize=12)

    # Ajouter les valeurs sur chaque barre
    for i, v in enumerate(comment_distribution):
        ax.text(i, v + 2, f'{v:.1f}%', ha='center', fontsize=10)

    # Afficher le graphique dans Streamlit
    st.pyplot(fig)
    st.write(" ")

#4eme graphique
# Calcul des pourcentages de valeurs manquantes
    missing_data = df.isnull().mean() * 100
    missing_data = missing_data.sort_values(ascending=False)

# Interface Streamlit
    st.write("### Analyse des valeurs manquantes")
    st.write(" ")

    # Cr√©ation du graphique
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x=missing_data.index, y=missing_data.values, palette='viridis', ax=ax)

    # Ajouter des titres et labels
    ax.set_title('Pourcentage de valeurs manquantes par colonne', fontsize=14)
    ax.set_xlabel('Colonnes', fontsize=12)
    ax.set_ylabel('Pourcentage de valeurs manquantes (%)', fontsize=12)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)  # Rotation pour lisibilit√©

    # Affichage dans Streamlit
    st.pyplot(fig)
    st.write(" ")

#5eme graphique
# Interface Streamlit
    st.write("### D√©tection des valeurs aberrantes avec Boxplots")
    st.write(" ")
    # Cr√©ation du graphique avec 6 subplots (2 lignes, 3 colonnes)
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))

    groupes = {
        'ATP': ['ATP'],
        'Rankings': ['WRank', 'LRank'],
        'Sets': ['Best of', 'Lsets', 'Wsets'],
        'Cotes': ['PSW', 'PSL', 'B365W', 'B365L'],
        'Elo': ['elo_winner', 'elo_loser'],
        'Proba_elo': ['proba_elo']}

    # Boucle pour cr√©er les boxplots dans chaque sous-figure
    for i, (groupe, variables) in enumerate(groupes.items()):    
        ax = axes[i // 3, i % 3]  # Position dans la grille
        sns.boxplot(data=df[variables], ax=ax, palette="Set2")  # Cr√©ation du boxplot
        ax.set_title(f'Boxplot pour {groupe}', fontsize=14)
        ax.set_xlabel('Variables', fontsize=12)
        ax.set_ylabel('Valeurs', fontsize=12)
        ax.tick_params(axis='x', rotation=45)

    # Ajustement du layout pour √©viter le chevauchement des titres
    plt.tight_layout()

    # Affichage du graphique dans Streamlit
    st.pyplot(fig)
    st.write(" ")

#6eme graphique
    st.write("### Afficher la distribution de la variable cible")
    st.write(" ")

    def target(row):
        if row["WRank"] > row["LRank"]:
            return 1
        else:
            return 0
    df['target'] = df.apply(lambda row: target(row), axis = 1)

    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x=df['target'].value_counts().index,
    y=df['target'].value_counts().values,
    palette='viridis')

# Ajouter les annotations directement sur les barres
    values = df['target'].value_counts().values
    labels = df['target'].value_counts().index

    for i in range(len(values)):
        plt.text(i, values[i] + 0.5, str(values[i]), ha='center', fontsize=12, fontweight='bold')

    ax.set_title("R√©partition de la variable cible", fontsize=14)
    ax.set_xlabel("Classes", fontsize=12)
    ax.set_ylabel("Nombre d'occurrences", fontsize=12)
    st.pyplot(fig)


df = df.drop(['B365W', 'B365L', 'PSL', 'PSW', 'Winner', 'Loser', 'Tournament', 'Location'], axis = 1)

df['Date'] = pd.to_datetime(df['Date'])
df['Month'] = df['Date'].dt.month

df = df[df["Comment"] == "Completed"]

df = df.drop(['Comment'], axis = 1)
df = df.drop(['Date'], axis = 1)

def target(row):
    if row["WRank"] > row["LRank"]:
        return 1
    else:
        return 0
df['target'] = df.apply(lambda row: target(row), axis = 1)
df = df.drop(columns=['Wsets', 'Lsets', 'proba_elo'])

if page == pages[3] :
    st.title("Nettoyage des donn√©es")
  
    st.write("Apr√®s cette premi√®re exploration, l'objectif est de nettoyer le dataset pour √©liminer les erreurs, incoh√©rences et valeurs manquantes qui pourraient fausser les analyses, r√©duire la pr√©cision des mod√®les et conduire √† des d√©cisions erron√©es. Voici les modifications r√©alis√©es :")
  
    st.write("### - Modification du format de la date")
    st.write("Comme expliqu√© pr√©c√©demment, la variable <span style='color:red'>Date</span> n‚Äô√©tait pas dans un format exploitable (conversion au format ‚Äòdatetime‚Äô). De plus, je souhaite identifier les tendances saisonni√®res dans les performances des joueurs ou des tournois donc je cr√©√© une nouvelle variable num√©rique <span style='color:red'>Month</span> qui repr√©sente le mois du match (format MM) √† partir de la variable <span style='color:red'>Date</span>.", unsafe_allow_html=True)
  
    st.write("### - Suppression des colonnes inutiles")
    st.write("Je d√©cide ensuite de supprimer les variables <span style='color:red'>PSW, PSL, B365W, B365L</span>. Elles correspondent aux c√¥tes des bookmakers qui seront utilis√©es √† des fins ult√©rieures pour comparer les r√©sultats mon mod√®le. De plus, les variables <span style='color:red'>Winner et Loser</span> qui font r√©f√©rence aux noms des vainqueurs et des perdants de chaque match ont aussi √©t√© supprim√©es puisqu‚Äôelles n‚Äôapportent aucune information pour pr√©dire le vainqueur. A l‚Äôinverse, la variable <span style='color:red'>proba_elo</span> qui correspond √† la probabilit√© qu‚Äôavait le vainqueur de gagner d‚Äôapr√®s son classement Elo, donne trop d‚Äôinformation quant √† l‚Äôidentit√© du vainqueur au mod√®le donc je la supprime √©galement.", unsafe_allow_html=True)
    st.write("Puis, je remarque que les colonnes <span style='color:red'>Location et Tournament</span> sont assez similaires de par la fr√©quence de leurs modalit√©s. Si une variable a une distribution de ses valeurs relativement √©gale (c'est-√†-dire uniforme), cela signifie qu'elle ne pr√©sente pas de tendance ou de structure exploitable par un mod√®le de machine learning. En d'autres termes, elle ne varie pas de mani√®re corr√©l√©e avec la variable cible √† pr√©dire. C‚Äôest pourquoi, je d√©cide de les supprimer √† leur tour.", unsafe_allow_html=True)
    
    st.write("### - Gestion des valeurs manquantes")
    st.write("En examinant les lignes du jeu de donn√©es, je remarque que les valeurs manquantes se trouvent presque uniquement dans les matchs qui n‚Äôont pas √©t√© termin√©s (modalit√© de <span style='color:red'>Comment</span> autre que **‚ÄòCompleted‚Äô**). Pour nettoyer les donn√©es, on d√©cide de conserver uniquement les matchs termin√©s. A la suite de cette op√©ration **il reste une unique ligne** o√π les valeurs <span style='color:red'>Wsets et Lsets</span> ne sont pas renseign√©es. ", unsafe_allow_html=True)
        
    st.write("### - Suppression de nouvelles colonnes")
    st.write("Apr√®s avoir cr√©√© une nouvelle variable <span style='color:red'>Month</span>, la variable <span style='color:red'>Date</span> n‚Äôest plus utile. De plus, apr√®s avoir supprim√© toutes les modalit√©s de la variable <span style='color:red'>Comment</span> pour ne laisser que **‚ÄòCompleted‚Äô**, celle-ci devient √©galement inutile mes mod√®le. Je les supprime toutes les deux.", unsafe_allow_html=True) 
    st.write("De plus, les variables <span style='color:red'>Wsets et Lsets</span> correspondent respectivement au nombre de sets gagn√©s par le vainqueur et au nombre de sets gagn√©s par le perdant, ce sont des informations connues seulement apr√®s un match donc qui ne doivent pas √™tre int√©gr√©es au mod√®le par souci de fuite des donn√©es. L‚Äôobjectif du mod√®le est de pr√©dire l‚Äôissue d‚Äôun match avant qu‚Äôil n‚Äôait eu lieu. Suite √† ces suppressions, **il ne reste plus aucune valeur manquante** dans les donn√©es.", unsafe_allow_html=True)
        
    st.write("### - Cr√©ation d'un variable cible")
    st.write("Dans un mod√®le de Machine Learning, il est essentiel d‚Äôavoir une variable cible qui repr√©sente la valeur que j'essaye de pr√©dire : ‚Äúquel joueur va gagner le match ?‚Äù. Le mod√®le ajuste ensuite ses poids et coefficients en fonction des erreurs qu‚Äôil commet par rapport √† la variable cible.")
    st.write("Je cr√©√© ainsi la variable <span style='color:red'>target</span> qui servira de variable cible. Le sujet concerne un probl√®me de classification binaire : le vainqueur est l‚Äôun des 2 joueurs. C‚Äôest pourquoi j'utilise une condition sur les variables <span style='color:red'>WRank</span> (classement du gagnant) et <span style='color:red'>LRank</span> (classement du perdant) pour la cr√©er.", unsafe_allow_html=True)
    st.write("Celle-ci prend les valeurs suivantes :")
    st.write("0 : Le joueur le mieux class√© au classement ATP gagne le match (victoire attendue).")
    st.write("1 : Le joueur le moins bien class√© au classement ATP gagne le match (victoire surprenante).")
    
    st.write("### - Analyse des corr√©lations entre les variables")
    st.write("En machine learning, une matrice de corr√©lation permet d'analyser les relations entre les variables explicatives (features) et aussi avec la variable cible. Cela aide √† mieux comprendre les donn√©es et √† optimiser la performance du mod√®le.")
    st.write("En effet, si deux variables explicatives sont fortement corr√©l√©es, elles apportent la m√™me information. De la m√™me mani√®re, une variable qui a une corr√©lation tr√®s faible avec toutes les autres (y compris avec la variable cible) est peu utile pour la pr√©diction.", unsafe_allow_html=True)
    st.write("Suite √† cette analyse, je supprime les variables <span style='color:red'>ATP et Best of</span>.", unsafe_allow_html=True)
    
    if st.checkbox("Afficher la Heatmap de corr√©lation"):
        st.write("### üî• Heatmap des corr√©lations")

    # Calcul de la matrice de corr√©lation
        numerical_cols = df.select_dtypes(include=['number'])  # S√©lection des colonnes num√©riques
        correlation_matrix = numerical_cols.corr()

        # Cr√©ation de la heatmap
        fig, ax = plt.subplots(figsize=(12, 8))
        sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm",
            vmin=-1, vmax=1, linewidths=0.5, square=True, ax=ax)
        ax.set_title("Matrice de corr√©lation entre les variables", fontsize=14)

        st.pyplot(fig)

df = df.drop(columns=["ATP", "Best of"])

if page == pages[3] :

    st.write("### Informations sur le dataframe apr√®s nettoyage")
    import io
    buffer = io.StringIO()
    df.info(buf=buffer)
    info_string = buffer.getvalue()

    # Affiche les informations dans un conteneur code
    st.code(info_string, language="text")

#df = df.drop(columns=["ATP", "Best of"])
X = df.drop(columns=["target"])  # Variables explicatives
y = df["target"]  # Variable cible
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
colonnes_a_encoder = ['Month', 'Surface', 'Court']
ohe.fit(X_train[colonnes_a_encoder])
X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
X_train = X_train.drop(columns=['Series', 'Round'])
X_test = X_test.drop(columns=['Series', 'Round'])
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

dtc = DecisionTreeClassifier()
dtc.fit(X_train, y_train)
y_pred_dtc = dtc.predict(X_test)

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.iloc[:, 0:4])
X_test_scaled = scaler.transform(X_test.iloc[:, 0:4])
X_train.iloc[:, 0:4] = X_train_scaled
X_test.iloc[:, 0:4] = X_test_scaled

reglog = LogisticRegression()
reglog.fit(X_train_scaled, y_train)
y_pred_reglog = rf.predict(X_test)

svm_model = SVC(kernel='linear', probability=True, random_state=42)
svm_model.fit(X_train_scaled, y_train)
y_pred_svm = svm_model.predict(X_test_scaled)

knn_model = KNeighborsClassifier(n_neighbors=1)
knn_model.fit(X_train_scaled, y_train)
y_pred_knn = knn_model.predict(X_test_scaled)


if page == pages[4] :
    st.title("Pr√©paration pour l'entrainement des mod√®les")

    st.write("### S√©paration des variables explicatives et de la variable cible en un jeu d'entrainement et un jeu de test")
    if st.checkbox("Afficher le code"):
        st.code("""
            X = df.drop(columns=["target"])  # Variables explicatives
            y = df["target"]  # Variable cible
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            """, language="python")
    
    st.write("### Encodage des variables cat√©gorielles avec OneHotEncoder")
    if st.checkbox("Afficher le code de l'encodage"):
        st.code("""
            # Instanciation de l'encodeur
            ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
            colonnes_a_encoder = ['Month', 'Surface', 'Court']
        
            # Encodage des variables cat√©gorielles et transformation en DataFrame
            ohe.fit(X_train[colonnes_a_encoder])
            X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
            X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
            train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
            test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
            X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
            X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
            """, language="python")

    st.write("### Encodage ordinal des variables avec une hi√©rarchie")
    if st.checkbox("Afficher le code de l'encodage ordinal"): 
        st.code("""
            # D√©finition des hi√©rarchies pour les variables 'Series' et 'Round'
            series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
            round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
        
            # Encodage ordinal de la variable Series
            ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
            X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
            X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
        
            # Encodage ordinal de la variable Round
            ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
            X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
            X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
            """, language="python")
    
    st.write("### Suppression des colonnes originales")
    if st.checkbox("Afficher le code de suppression"):
        st.code("""
            X_train = X_train.drop(columns=['Series', 'Round'])
            X_test = X_test.drop(columns=['Series', 'Round'])
            """, language="python")
    
    st.write("### Standardisation des donn√©es")
    if st.checkbox("Afficher le code de standardisation"):
        st.code("""
            # Instanciation du StandardScaler
            scaler = StandardScaler()
        
            # Standardisation des variables explicatives (les 4 premi√®res colonnes)
            X_train_scaled = scaler.fit_transform(X_train.iloc[:, 0:4])
            X_test_scaled = scaler.transform(X_test.iloc[:, 0:4])
            X_train.iloc[:, 0:4] = X_train_scaled
            X_test.iloc[:, 0:4] = X_test_scaled
            """, language="python")
    
    st.write("### Sur-√©chantillonnage des donn√©es d'entra√Ænement")
    if st.checkbox("Afficher le code du sur-√©chantillonnage"):
        st.code("""
            # Instanciation de l'objet SMOTE et application sur les donn√©es d'entra√Ænement
            smote = SMOTE(random_state=42)
            X_train, y_train = smote.fit_resample(X_train, y_train)
            """, language="python")

    st.write("### Taille de mes √©chantillons avant entra√Ænement des mod√®les")
    st.write(f"**Taille du jeu d'entra√Ænement** : {X_train.shape[0]} lignes dont {y_train.sum()} de la classe 1 et {y_train.shape[0] - y_train.sum()} de la classe 0")
    st.write(f"**Taille du jeu de test** : {X_test.shape[0]} lignes dont {y_test.sum()} de la classe 1 et {y_test.shape[0] - y_test.sum()} de la classe 0")
    
if page == pages[5] :
    st.write("### Machine learning")
    
    if st.checkbox("Afficher un aper√ßu du jeu d'entra√Ænement") :
        st.dataframe(X_train.head(10))
    options=["Arbre de classification","KNN","SVM","Random Forest","Logistic Regression"]
    choix=st.selectbox("Selection de l'algorithme de machine learning", options)
    st.markdown(f"# **{choix}**")

    test_size = st.slider("Proportion du jeu de test", min_value=0.1, max_value=0.5, step=0.05, value=0.2)
    st.write(f"Le jeu de test repr√©sentera {test_size*100:.0f}% des donn√©es.")

# Division des donn√©es
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

# Mod√®le s√©lectionn√©
    if choix == "Random Forest":
        ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
        colonnes_a_encoder = ['Month', 'Surface', 'Court']
        ohe.fit(X_train[colonnes_a_encoder])
        X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
        X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
        train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
        test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
        X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
        X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
        series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
        round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
        ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
        X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
        ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
        X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
        X_train = X_train.drop(columns=['Series', 'Round'])
        X_test = X_test.drop(columns=['Series', 'Round'])
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)
        
    #Entrainement du mod√®le
        model = RandomForestClassifier()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Pr√©cision du mod√®le {choix} : {accuracy:.2f}")

    # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        st.write("### Matrice de confusion")
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        st.pyplot(fig)
    
    # Rapport de classification
        st.write("### Rapport de classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        st.dataframe(pd.DataFrame(report).transpose())
        
# Mod√®le s√©lectionn√©
    if choix == "Arbre de classification":
        ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
        colonnes_a_encoder = ['Month', 'Surface', 'Court']
        ohe.fit(X_train[colonnes_a_encoder])
        X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
        X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
        train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
        test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
        X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
        X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
        series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
        round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
        ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
        X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
        ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
        X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
        X_train = X_train.drop(columns=['Series', 'Round'])
        X_test = X_test.drop(columns=['Series', 'Round'])
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)
        
    #Entrainement du mod√®le
        model = DecisionTreeClassifier()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Pr√©cision du mod√®le {choix} : {accuracy:.2f}")

    # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        st.write("### Matrice de confusion")
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        st.pyplot(fig)
    
    # Rapport de classification
        st.write("### Rapport de classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        st.dataframe(pd.DataFrame(report).transpose())
        
    if choix == "KNN":
        ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
        colonnes_a_encoder = ['Month', 'Surface', 'Court']
        ohe.fit(X_train[colonnes_a_encoder])
        X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
        X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
        train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
        test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
        X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
        X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
        series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
        round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
        ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
        X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
        ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
        X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
        X_train = X_train.drop(columns=['Series', 'Round'])
        X_test = X_test.drop(columns=['Series', 'Round'])
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train.iloc[:, 0:4])
        X_test_scaled = scaler.transform(X_test.iloc[:, 0:4])
        X_train.iloc[:, 0:4] = X_train_scaled
        X_test.iloc[:, 0:4] = X_test_scaled
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)
        
    #Entrainement du mod√®le
        k = st.slider("Choisissez le nombre de voisins (k)", min_value=1, max_value=5, step=1, value=5)
        model = KNeighborsClassifier(n_neighbors=k)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Pr√©cision du mod√®le {choix} : {accuracy:.2f}")

    # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        st.write("### Matrice de confusion")
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        st.pyplot(fig)
    
    # Rapport de classification
        st.write("### Rapport de classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        st.dataframe(pd.DataFrame(report).transpose())
        
    if choix == "SVM":
        ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
        colonnes_a_encoder = ['Month', 'Surface', 'Court']
        ohe.fit(X_train[colonnes_a_encoder])
        X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
        X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
        train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
        test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
        X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
        X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
        series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
        round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
        ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
        X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
        ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
        X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
        X_train = X_train.drop(columns=['Series', 'Round'])
        X_test = X_test.drop(columns=['Series', 'Round'])
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train.iloc[:, 0:4])
        X_test_scaled = scaler.transform(X_test.iloc[:, 0:4])
        X_train.iloc[:, 0:4] = X_train_scaled
        X_test.iloc[:, 0:4] = X_test_scaled
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)
        
    #Entrainement du mod√®le
        model = SVC()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Pr√©cision du mod√®le {choix} : {accuracy:.2f}")

    # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        st.write("### Matrice de confusion")
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        st.pyplot(fig)
    
    # Rapport de classification
        st.write("### Rapport de classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        st.dataframe(pd.DataFrame(report).transpose())
     
    if choix == "Logistic Regression":
        ohe = OneHotEncoder(drop='first', sparse_output= False, handle_unknown='ignore')
        colonnes_a_encoder = ['Month', 'Surface', 'Court']
        ohe.fit(X_train[colonnes_a_encoder])
        X_train_encode = ohe.fit_transform(X_train[colonnes_a_encoder])
        X_test_encode = ohe.transform(X_test[colonnes_a_encoder])
        train_encoded_df = pd.DataFrame(X_train_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_train.index)
        test_encoded_df = pd.DataFrame(X_test_encode, columns=ohe.get_feature_names_out(colonnes_a_encoder), index=X_test.index)
        X_train = pd.concat([X_train.drop(columns=colonnes_a_encoder), train_encoded_df], axis=1)
        X_test = pd.concat([X_test.drop(columns=colonnes_a_encoder), test_encoded_df], axis=1)
        series_order = ['Grand Slam', 'Masters 1000', 'Masters', 'ATP 500', 'Masters Cup', 'International Gold', 'ATP 250', 'International']
        round_order = ['The Final', 'Semifinals', 'Quarterfinals', '3rd Round', '2nd Round', '1st Round', 'Round Robin']
        ordinal_encoder_series = OrdinalEncoder(categories=[series_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Series_encoded'] = ordinal_encoder_series.fit_transform(X_train[['Series']])
        X_test['Series_encoded'] = ordinal_encoder_series.transform(X_test[['Series']])
        ordinal_encoder_round = OrdinalEncoder(categories=[round_order], handle_unknown='use_encoded_value', unknown_value=-1)
        X_train['Round_encoded'] = ordinal_encoder_round.fit_transform(X_train[['Round']])
        X_test['Round_encoded'] = ordinal_encoder_round.transform(X_test[['Round']])
        X_train = X_train.drop(columns=['Series', 'Round'])
        X_test = X_test.drop(columns=['Series', 'Round'])
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train.iloc[:, 0:4])
        X_test_scaled = scaler.transform(X_test.iloc[:, 0:4])
        X_train.iloc[:, 0:4] = X_train_scaled
        X_test.iloc[:, 0:4] = X_test_scaled
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)
        
    #Entrainement du mod√®le
        model = LogisticRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        st.write(f"Pr√©cision du mod√®le {choix} : {accuracy:.2f}")

    # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        st.write("### Matrice de confusion")
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        st.pyplot(fig)
    
    # Rapport de classification
        st.write("### Rapport de classification")
        report = classification_report(y_test, y_pred, output_dict=True)
        st.dataframe(pd.DataFrame(report).transpose())

model_metrics = {}

# Liste des mod√®les et de leurs pr√©dictions
models = {
    "Arbre de classification": y_pred_dtc,
    "Random Forest": y_pred_rf,
    "R√©gression logistique": y_pred_reglog,
    "SVM": y_pred_svm,
    "KNN": y_pred_knn,  
    }

# Calcul des m√©triques pour chaque mod√®le
for model_name, y_pred in models.items():
    model_metrics[model_name] = {
        "Accuracy": round(accuracy_score(y_test, y_pred), 3),
        "Precision": round(precision_score(y_test, y_pred), 3),
        "Recall": round(recall_score(y_test, y_pred), 3),
        "F1-Score": round(f1_score(y_test, y_pred), 3)
        }

# Cr√©ation du DataFrame
df_metrics = pd.DataFrame.from_dict(model_metrics, orient='index')
    
if page == pages[5] :
    st.write("### Tableau r√©capitulatif des m√©triques par mod√®le (performances sur la classe positive : victoire surprise)")
    st.dataframe(df_metrics)

proba_rf = rf.predict_proba(X_test)[:, 1]
proba_reglog = reglog.predict_proba(X_test_scaled)[:, 1]
proba_knn = knn_model.predict_proba(X_test_scaled)[:, 1]
proba_dtc = dtc.predict_proba(X_test)[:, 1]
proba_svm = svm_model.predict_proba(X_test_scaled)[:, 1]  # Seulement si SVC(probability=True)

df_results = pd.DataFrame({
    'Actual_Winner': y_test,  # Vraie issue du match
    'proba_RandomForest': proba_rf,
    'proba_LogReg': proba_reglog.round(2),
    'proba_KNN': proba_knn,
    'proba_Tree': proba_dtc,
    'proba_SVM': proba_svm.round(2),
    })

# Comparaison des probabilit√©s de victoire des bookmakers et du mod√®le Random Forest
# r√©cup√©ration des donn√©es d'origine
df1 = pd.read_csv('atp_data.csv')
df1['target'] = df.apply(lambda row: target(row), axis = 1)

# Extraire les cotes des bookmakers pour les matchs de test et calcul de la probabilit√© associ√©e
cotes_bookmakers = df1.loc[X_test.index, ['B365W', 'B365L', 'PSL', 'PSW', 'target', 'proba_elo']]
cotes_bookmakers['proba_PSL']= 1/cotes_bookmakers['PSL']
cotes_bookmakers['proba_B365W']= 1/cotes_bookmakers['B365W']
cotes_bookmakers['proba_PSW']= 1/cotes_bookmakers['PSW']
cotes_bookmakers['proba_B365L']= 1/cotes_bookmakers['B365L']

# Concat√©nation des probabilit√©s des bookmakers et du mod√®le Random Forest
proba_rf_df = pd.DataFrame(df_results, columns=['proba_RandomForest'])
df_comparison = pd.concat([cotes_bookmakers, proba_rf_df], axis=1)

#Extraire les donn√©es lorsque target == 1
df_target_1 = df_comparison[df_comparison['target'] == 1]
df_target_1 = df_target_1.drop(columns=['target', 'B365L', 'PSL', 'proba_PSL', 'proba_B365L'], axis=1)

if page == pages[6] :
    st.write("### Calcul des probabilit√©s")
    
    st.write("Calcul des probabilit√©s que le joueur le moins bien class√© gagne pour chaque mod√®le (victoire surprise) :")
    st.dataframe(df_results.head(10))

    st.write("Comparaison des probabilit√©s de victoire des bookmakers et celle du Random Forest (victoire surprise) :")
    st.dataframe(df_target_1.head(10))


if page == pages[7] :
    
    pct_RF_vs_B365W = (df_target_1['proba_RandomForest'] > df_target_1['proba_B365W']).mean() * 100
    pct_RF_vs_PSW = (df_target_1['proba_RandomForest'] > df_target_1['proba_PSW']).mean() * 100

    st.write("### Conclusion")
    st.write("Suite √† la comparaison des cas pour lesquels la probabilit√© du Random Forest d‚Äôobtenir une victoire surprise (lorsque c‚Äôest r√©ellement le cas, c‚Äôest √† dire lorsque target = 1) est sup√©rieure √† celles donn√©es par les c√¥tes des bookmakers, j'obtiens les r√©sultats suivants :") 
    st.write(f"- Le mod√®le Random Forest est meilleur que le bookmaker Bet365 dans **{pct_RF_vs_B365W:.2f}%** des cas")
    st.write(f"- Le mod√®le Random Forest est meilleur que le bookmaker Pinnacles Sport dans **{pct_RF_vs_PSW:.2f}%** des cas")
    st.write("**Je n‚Äôobtiens pas de meilleurs r√©sultats que les bookmakers** dans plus de la moiti√© des cas comme je le souhaitais au d√©part.")
    st.write("La strat√©gie pourrait √™tre encore affin√©e en √©tablissant un seuil d√©cisionnel pour maximiser le rapport risque/rendement, potentiellement en se concentrant sur les matchs o√π mon mod√®le attribue une probabilit√© sup√©rieure √† 0.45 √† une surprise, m√™me lorsque cette valeur reste inf√©rieure √† 0.5.")
    st.write("Pour battre les bookmakers, je devrais envisager d'int√©grer des facteurs compl√©mentaires (variance historique des performances, les sp√©cificit√©s des surfaces, l'historique des confrontations directes, ou l'√©tat de forme r√©cent) afin de construire un syst√®me de paris sophistiqu√© capable d'exploiter syst√©matiquement les inefficiences du march√©.")
